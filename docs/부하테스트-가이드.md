# 부하테스트 완전 정복 가이드

> 처음 부하테스트를 하는 개발자를 위한 실전 가이드

## 목차
1. [부하테스트를 왜 하는가?](#부하테스트를-왜-하는가)
2. [부하테스트로 무엇을 알아낼 수 있는가?](#부하테스트로-무엇을-알아낼-수-있는가)
3. [핵심 지표 이해하기](#핵심-지표-이해하기)
4. [실전 테스트 시나리오](#실전-테스트-시나리오)
5. [학습 로드맵](#학습-로드맵)

---

## 부하테스트를 왜 하는가?

### 서버 개발자의 영원한 고민들

서버를 만들 때 항상 마주하는 질문들:

```
❓ 쓰레드풀을 몇 개로 설정해야 할까?
❓ DB 커넥션 풀은 몇 개가 적정할까?
❓ 동시 사용자 몇 명까지 버틸 수 있을까?
❓ 서버를 몇 대 띄워야 할까?
```

이런 질문들에 **"감"으로 답하면 망합니다.**

### 감으로 하면 생기는 일

**사례 1: 과소 설정**
```java
// 쓰레드풀을 10개로 설정
ExecutorService executor = Executors.newFixedThreadPool(10);

// 결과
- 실제로는 100명이 동시 접속
- 90명은 대기... 대기... 타임아웃!
- 고객 이탈, 서비스 평점 폭락
```

**사례 2: 과대 설정**
```java
// 불안해서 쓰레드풀을 1000개로 설정
ExecutorService executor = Executors.newFixedThreadPool(1000);

// 결과
- 실제로는 50명만 접속
- 950개의 쓰레드가 놀고 있음
- 메모리 낭비, 컨텍스트 스위칭 오버헤드
- 서버 비용만 증가
```

### 부하테스트의 목적

**"측정하지 않으면 개선할 수 없다"**

부하테스트는:
- 🔍 **현재 시스템의 한계를 파악**하고
- 📊 **데이터 기반으로 설정값을 최적화**하며
- 🚨 **운영 전에 문제를 미리 발견**합니다

---

## 부하테스트로 무엇을 알아낼 수 있는가?

### 1. 병목 지점 찾기 (가장 중요!)

**증상:**
```
부하테스트 결과:
- CPU 사용률: 20%
- 메모리: 30%
- 응답시간: 10초

뭔가 이상하다... 자원은 남는데 왜 느려?
```

**원인 분석:**
```java
// 원인: 쓰레드풀이 너무 작음
ExecutorService executor = Executors.newFixedThreadPool(10);

// 해결: 쓰레드풀 증가
ExecutorService executor = Executors.newFixedThreadPool(100);

// 결과: 응답시간 10초 → 2초로 개선!
```

**병목의 종류:**
- CPU 병목: CPU 사용률 100%, 계산 작업 많음
- 메모리 병목: OOM 에러, GC 과다
- 네트워크 병목: 대역폭 한계
- **쓰레드 병목**: 쓰레드풀 부족 ← 가장 흔함!
- DB 병목: 커넥션 풀 부족, 슬로우 쿼리

### 2. 한계점(Limit) 찾기

**실험:**
```
동시 사용자  |  평균 응답시간  |  에러율
----------|--------------|--------
50명      |  0.5초       |  0%    ✅
100명     |  1.2초       |  2%    ⚠️
200명     |  5.0초       |  15%   ❌
500명     |  30초        |  80%   💀
```

**분석:**
- **안전 구간**: VU 100까지 (에러율 2% 이하)
- **위험 구간**: VU 200부터 (에러율 급증)
- **임계점**: VU 150 정도로 추정

**액션:**
```
1. 현재 설정: VU 100까지 안전
2. 목표 트래픽: VU 300 필요
3. 스케일링 전략:
   - 수평 확장: 서버 3대로 분산
   - 또는 수직 확장: 쓰레드풀, 메모리 증설
```

### 3. 최적 설정값 찾기 (핵심!)

**실험: 쓰레드풀 크기별 성능 비교**

```
실험 조건: VU 200 고정

쓰레드 50개:
  - 평균 응답: 8초
  - 처리량: 25 req/s
  - CPU: 40%

쓰레드 100개:
  - 평균 응답: 2초  ← 개선!
  - 처리량: 100 req/s ← 4배 증가!
  - CPU: 70%

쓰레드 200개:
  - 평균 응답: 2초  ← 차이 없음
  - 처리량: 100 req/s ← 차이 없음
  - CPU: 70%

쓰레드 500개:
  - 평균 응답: 2.5초 ← 오히려 나빠짐
  - 처리량: 90 req/s
  - CPU: 80% (컨텍스트 스위칭 오버헤드)
```

**결론:**
- **최적값: 쓰레드 100개**
- 50개는 부족 (병목 발생)
- 200개 이상은 낭비 (성능 개선 없음)
- 500개는 오히려 악화 (오버헤드 증가)

### 4. 재시도 전략 검증

**외부 API 호출 시나리오 (현재 프로젝트)**

```java
// Mock 서버 특성
- 평균 응답시간: 4초
- 실패율: 33%
- 최대 지연: 30초

// 재시도 전략 A: 즉시 재시도
재시도 1회: 추가 4초 대기
재시도 2회: 추가 4초 대기
총 소요시간: 12초

// 재시도 전략 B: 지수 백오프
재시도 1회: 1초 후 재시도
재시도 2회: 2초 후 재시도
총 소요시간: 7초 (더 효율적!)
```

**부하테스트로 검증:**
```
전략 A (즉시 재시도):
  - p95 응답시간: 15초
  - 서버 부하: 높음

전략 B (지수 백오프):
  - p95 응답시간: 10초 ← 개선!
  - 서버 부하: 낮음
```

---

## 핵심 지표 이해하기

### 실제 테스트 결과 분석 (본 프로젝트)

```
     execution: local
        script: k6/load-test.js

     scenarios: Up to 200 VUs for 6m30s

  ✓ 정상 응답

     HTTP
     http_req_duration..............: avg=3.95s min=785.1µs med=2.76s max=30s p(90)=9.08s p(95)=11.86s
     http_req_failed................: 33.78% 2824 out of 8359
     http_reqs......................: 8359   20.742353/s

     EXECUTION
     iteration_duration.............: avg=3.95s min=785.1µs med=2.76s max=30s p(90)=9.08s p(95)=11.86s
     iterations.....................: 8359   20.742353/s
     vus............................: 1      min=1            max=200
```

### 1. 응답시간 (http_req_duration)

**지표 설명:**
```
avg (평균):    3.95초
min (최소):    785.1µs (0.78ms)
med (중앙값):  2.76초
max (최대):    30초
p(90):         9.08초
p(95):         11.86초
```

**왜 평균보다 p95가 중요한가?**

```
사용자 100명의 응답시간:
95명: 2초
5명:  30초

평균: (95×2 + 5×30) / 100 = 3.4초  ← 괜찮아 보임
p95:  2초                            ← 95%는 만족!
```

**평균의 함정:**
- 극단값(outlier)에 영향을 많이 받음
- 대부분 사용자의 실제 경험을 반영 못함

**p95의 의미:**
- **95%의 사용자가 경험하는 시간**
- 나머지 5%는 재시도, 네트워크 등 특수 상황
- SLA 설정 시 기준: "p95 < 3초"

### 2. 처리량 (throughput)

**지표:**
```
http_reqs: 8359 (20.742353/s)
```

**주의! 평균의 함정:**

테스트는 6분 30초 동안 진행:
- VU 10 (1분 30초)
- VU 50 (1분 30초)
- VU 100 (1분 30초)
- VU 200 (1분 30초)

**전체 평균 20 req/s는 의미 없음!**

**실제 처리량 계산:**
```
시간      VU    누적 요청   구간 처리량
2분까지   50    413개      ~3.4 req/s
4분까지   100   2,474개    ~17.2 req/s
6분까지   200   7,387개    ~40.9 req/s  ← 진짜 처리량!
```

**VU 200일 때 실제 처리량: 약 41 req/s**

### 3. 실패율 (http_req_failed)

**지표:**
```
http_req_failed: 33.78% (2824 out of 8359)
```

**본 프로젝트의 경우:**
- Mock 서버가 의도적으로 1/3 확률로 500 에러 발생
- 실제 운영 환경에서는 0%에 가까워야 함

**목표 기준:**
- 일반 API: < 0.1%
- 높은 가용성 API: < 0.01%
- 미션 크리티컬: < 0.001%

### 4. VU (Virtual Users)

**오해하기 쉬운 점:**

```
❌ VU 200 = 200명의 사용자
✅ VU 200 = 동시에 요청 보내는 가상 유저 200명

실제 동시 접속자는 더 많을 수 있음!
```

**실제 사용자와의 관계:**

```
실제 사용자 1000명
- 대기 중: 700명
- 페이지 읽는 중: 200명
- 실제 요청 보내는 중: 100명 ← VU 100

VU는 "액티브하게 요청 보내는 수"를 시뮬레이션
```

---

## 실전 테스트 시나리오

### 본 프로젝트의 목표

**시스템 구조:**
```
[클라이언트]
    ↓
[알람 미들웨어 서버] ← 개발 예정 (쓰레드풀 크기 미정)
    ↓ (비동기 요청)
[알람 Mock 서버] ← 테스트 완료
```

**Mock 서버 특성 (측정 완료):**
- 평균 응답시간: 3.95초
- p95 응답시간: 11.86초
- 최대 처리 가능: VU 200 (약 41 req/s)
- 의도적 에러율: 33%
- 지연 패턴: 지수분포 (평균 4초, 최대 30초)

### Step 1: Mock 서버 한계 파악 ✅ (완료)

**테스트 설정:**
```javascript
// k6/load-test.js
export const options = {
    stages: [
        { duration: '30s', target: 10 },
        { duration: '1m', target: 10 },
        { duration: '30s', target: 50 },
        { duration: '1m', target: 50 },
        { duration: '30s', target: 100 },
        { duration: '1m', target: 100 },
        { duration: '30s', target: 200 },
        { duration: '1m', target: 200 },
    ],
};
```

**결과:**
- VU 200까지 안정적으로 처리
- 평균 41 req/s 처리 가능
- 병목 없음 (의도적 지연만 존재)

### Step 2: 미들웨어 서버 개발

**기본 설계안:**

```java
@Configuration
public class AsyncConfig {
    @Bean
    public ThreadPoolTaskExecutor notificationExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(100);      // 일단 100으로 시작
        executor.setMaxPoolSize(200);
        executor.setQueueCapacity(500);
        executor.setThreadNamePrefix("notification-");
        executor.initialize();
        return executor;
    }
}

@Service
public class NotificationService {
    @Async("notificationExecutor")
    public CompletableFuture<Void> sendNotification(Request req) {
        // Mock 서버로 비동기 전송
        // 재시도 로직 포함
    }
}
```

**질문: 쓰레드풀 크기를 왜 100으로?**
- Little's Law: `동시 처리 = 처리량 × 응답시간`
- Mock 서버: `41 req/s × 3.95s ≈ 162개`
- 하지만 재시도, 큐잉 고려 → **100으로 시작해서 튜닝**

### Step 3: 미들웨어 성능 테스트 (다음 단계)

**실험 계획:**

**테스트 1: 쓰레드풀 크기별 비교**
```
조건: VU 200 고정, 1분 테스트

실험 A: 쓰레드 50개
실험 B: 쓰레드 100개
실험 C: 쓰레드 150개
실험 D: 쓰레드 200개

측정 지표:
- 응답시간 (avg, p95)
- 처리량 (req/s)
- CPU 사용률
- 메모리 사용량
- 큐 대기 시간
```

**테스트 2: 재시도 전략 비교**
```
조건: VU 200, 쓰레드 100개

전략 A: 재시도 없음
전략 B: 즉시 재시도 (최대 3회)
전략 C: 지수 백오프 (1s, 2s, 4s)

측정 지표:
- 최종 성공률
- 평균 응답시간
- Mock 서버 부하
```

**테스트 3: 한계 테스트**
```
조건: 최적 설정값 적용

VU를 점진적으로 증가:
10 → 50 → 100 → 200 → 500 → 1000

언제 터지는지 확인:
- 에러율 5% 초과 시점
- 응답시간 10초 초과 시점
- 메모리 부족 시점
```

### Step 4: 최적화 및 결론

**예상 결과 (가설):**

```
최적 설정:
- 쓰레드풀: 100-120개
- 큐 크기: 500
- 재시도: 지수 백오프 (최대 3회)
- 타임아웃: 15초
- 서킷 브레이커: 연속 10회 실패 시 차단

성능 목표:
- p95 < 5초
- 처리량 > 40 req/s
- 에러율 < 1% (Mock 에러 제외)
- 동시 처리: VU 200
```

---

## 학습 로드맵

### Phase 1: 기초 이해 (1-2주)

**1. 부하테스트 개념**
- [ ] 부하테스트 vs 스트레스테스트 vs 스파이크테스트
- [ ] VU, RPS, Latency 등 용어 이해
- [ ] k6 설치 및 기본 사용법

**실습:**
```javascript
// 간단한 첫 테스트
import http from 'k6/http';

export const options = {
    vus: 10,
    duration: '30s',
};

export default function () {
    http.get('http://localhost:8080');
}
```

**2. 핵심 지표 이해**
- [ ] 응답시간: avg, median, p95, p99
- [ ] 처리량: RPS (Requests Per Second)
- [ ] 에러율
- [ ] 자원 사용률: CPU, 메모리, 네트워크

**학습 자료:**
- k6 공식 문서: https://k6.io/docs/
- "Understanding Latency Percentiles" 글 읽기
- Grafana k6 대시보드 튜토리얼

### Phase 2: 실전 테스트 (2-3주)

**1. 시나리오 작성**
- [ ] Ramp-up 테스트 (점진적 부하 증가)
- [ ] Stress 테스트 (한계점 찾기)
- [ ] Spike 테스트 (급격한 트래픽 변화)
- [ ] Soak 테스트 (장시간 안정성)

**실습 예제:**
```javascript
// Ramp-up 테스트
export const options = {
    stages: [
        { duration: '1m', target: 50 },   // 워밍업
        { duration: '3m', target: 100 },  // 부하 증가
        { duration: '2m', target: 100 },  // 유지
        { duration: '1m', target: 0 },    // 종료
    ],
    thresholds: {
        http_req_duration: ['p(95)<500'], // p95는 500ms 이하
        http_req_failed: ['rate<0.01'],   // 에러율 1% 이하
    },
};
```

**2. 모니터링 설정**
- [ ] Grafana + Prometheus 연동
- [ ] JVM 메트릭 수집 (Micrometer)
- [ ] 쓰레드 풀 모니터링
- [ ] 실시간 대시보드 구성

**실습:**
- 본 프로젝트의 `grafana-dashboard.json` 활용
- Prometheus exporter 설정
- Custom metric 추가

**3. 병목 분석**
- [ ] CPU 병목 vs I/O 병목 구분
- [ ] 쓰레드 덤프 분석
- [ ] 힙 덤프 분석
- [ ] 네트워크 병목 확인

**도구:**
- jstack (쓰레드 덤프)
- jmap (힙 덤프)
- VisualVM (프로파일링)
- 혹은 IntelliJ Profiler

### Phase 3: 최적화 및 튜닝 (3-4주)

**1. 쓰레드풀 튜닝**
- [ ] Little's Law 이해 및 적용
- [ ] Core vs Max 쓰레드 설정
- [ ] 큐 크기 결정
- [ ] Rejection Policy 선택

**실험:**
```java
// 다양한 설정 테스트
실험 1: corePoolSize=50, maxPoolSize=100, queue=100
실험 2: corePoolSize=100, maxPoolSize=200, queue=500
실험 3: corePoolSize=150, maxPoolSize=300, queue=1000

각 설정별로 부하테스트 → 비교 분석
```

**2. 커넥션 풀 튜닝**
- [ ] HikariCP 설정 최적화
- [ ] maximumPoolSize 결정
- [ ] connectionTimeout 설정
- [ ] 모니터링 지표 확인

**3. JVM 튜닝**
- [ ] 힙 크기 설정 (-Xms, -Xmx)
- [ ] GC 알고리즘 선택
- [ ] GC 로그 분석
- [ ] GC 튜닝

### Phase 4: 고급 주제 (4주 이상)

**1. 분산 부하테스트**
- [ ] k6 Cloud 사용
- [ ] 여러 머신에서 동시 테스트
- [ ] 대규모 트래픽 시뮬레이션

**2. 카오스 엔지니어링**
- [ ] 의도적 장애 주입
- [ ] 네트워크 지연 시뮬레이션
- [ ] 서비스 다운 시뮬레이션
- [ ] 복구 능력 테스트

**3. 성능 회귀 테스트**
- [ ] CI/CD 파이프라인에 통합
- [ ] 성능 기준선(baseline) 설정
- [ ] 자동화된 성능 검증
- [ ] 성능 저하 알림

---

## 추천 학습 순서

### 🎯 초보자 (지금의 당신!)

**Week 1: 기본 개념**
```
1. k6 설치 및 첫 테스트 (1일)
2. 핵심 지표 이해 (2일)
3. 간단한 시나리오 작성 (2일)
```

**Week 2-3: 본 프로젝트 실습**
```
1. Mock 서버 부하테스트 (완료!)
2. 미들웨어 서버 개발
3. 미들웨어 부하테스트
4. 쓰레드풀 크기 최적화
```

**Week 4: 모니터링 & 분석**
```
1. Grafana 대시보드 구성
2. JVM 메트릭 수집
3. 병목 분석 실습
```

### 🚀 중급자

**집중 영역:**
- 복잡한 시나리오 작성 (인증, 세션, 다양한 API)
- 자동화된 성능 테스트 파이프라인
- 프로덕션 트래픽 리플레이
- A/B 테스트 기반 성능 비교

### 💪 고급자

**집중 영역:**
- 대규모 분산 테스트 (수만 VU)
- 카오스 엔지니어링
- 성능 최적화 컨설팅
- 커스텀 메트릭 및 분석 도구 개발

---

## 참고 자료

### 공식 문서
- [k6 공식 문서](https://k6.io/docs/)
- [Grafana k6 OSS](https://github.com/grafana/k6)
- [Spring Boot Actuator](https://docs.spring.io/spring-boot/docs/current/reference/html/actuator.html)

### 추천 블로그/글
- "How to use k6 for load testing" (k6 공식 블로그)
- "Understanding Latency Percentiles" (Gil Tene)
- "Little's Law in 3 minutes" (Medium)

### 도구
- k6: 부하테스트 도구
- Grafana: 시각화
- Prometheus: 메트릭 수집
- VisualVM/IntelliJ Profiler: 프로파일링

### 커뮤니티
- k6 Community Forum
- 한국 성능 엔지니어링 커뮤니티
- Stack Overflow [k6] 태그

---

## 마치며

**부하테스트는 예술이 아닌 과학입니다.**

- 측정하고
- 분석하고
- 개선하고
- 다시 측정합니다

**처음엔 어렵지만, 한 번 익히면 평생 써먹습니다.**

이 문서와 함께 여러분의 부하테스트 여정을 시작해보세요!

---

**프로젝트 정보:**
- Repository: NotificationMockServer
- 목적: 알람 미들웨어 서버 개발을 위한 Mock 서버 및 부하테스트 환경
- Tech Stack: Spring Boot, k6, Grafana, Prometheus

**작성일:** 2026-02-26
